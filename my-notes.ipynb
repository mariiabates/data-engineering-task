{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `GET` http://127.0.0.1:5000/v1/products/{product-id}/reviews/stats  \n",
    "The route returns aggregated review information for a product with a particular ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"productID\": \"0739079891\",\n",
      "  \"average\": 3.8,\n",
      "  \"percent_breakdown\": {\n",
      "    \"1_star\": 9,\n",
      "    \"2_star\": 6,\n",
      "    \"3_star\": 15,\n",
      "    \"4_star\": 30,\n",
      "    \"5_star\": 39\n",
      "  },\n",
      "  \"count_breakdown\": {\n",
      "    \"1_star\": 3,\n",
      "    \"2_star\": 2,\n",
      "    \"3_star\": 5,\n",
      "    \"4_star\": 10,\n",
      "    \"5_star\": 13\n",
      "  },\n",
      "  \"total\": 33\n",
      "}\n",
      "application/json\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/v1/products/0739079891/reviews/stats\"\n",
    "response = requests.get(url)\n",
    "parsed = json.loads(response.text)\n",
    "print(json.dumps(parsed, indent=2))\n",
    "print(response.headers.get('content-type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of your request you can pass a date as an integer in the form of Unix Timestamp to filter statistics by date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"productID\": \"0739079891\",\n",
      "  \"average\": 4.0,\n",
      "  \"percent_breakdown\": {\n",
      "    \"4_star\": 100\n",
      "  },\n",
      "  \"count_breakdown\": {\n",
      "    \"4_star\": 1\n",
      "  },\n",
      "  \"total\": 1\n",
      "}\n",
      "application/json\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/v1/products/0739079891/reviews/stats\"\n",
    "response = requests.get(url, params={\"date\": 1375056000})\n",
    "parsed = json.loads(response.text)\n",
    "print(json.dumps(parsed, indent=2))\n",
    "print(response.headers.get('content-type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can hit the route directly like below:  \n",
    "`GET` http://127.0.0.1:5000/v1/products/{product-id}/reviews/stats?date={unix-time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"productID\": \"0739079891\",\n",
      "  \"average\": 4.0,\n",
      "  \"percent_breakdown\": {\n",
      "    \"4_star\": 100\n",
      "  },\n",
      "  \"count_breakdown\": {\n",
      "    \"4_star\": 1\n",
      "  },\n",
      "  \"total\": 1\n",
      "}\n",
      "application/json\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/v1/products/0739079891/reviews/stats?date=1375056000\"\n",
    "response = requests.get(url)\n",
    "parsed = json.loads(response.text)\n",
    "print(json.dumps(parsed, indent=2))\n",
    "print(response.headers.get('content-type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `GET` http://127.0.0.1:5000/v1/customers/{customer-id}/reviews/stats  \n",
    "The route returns aggregated review information for a user with a particular ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"customerID\": \"A224LOZUTJTM3O\",\n",
      "  \"average\": 4.8,\n",
      "  \"total\": 5\n",
      "}\n",
      "application/json\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/v1/customers/A224LOZUTJTM3O/reviews/stats\"\n",
    "response = requests.get(url)\n",
    "parsed = json.loads(response.text)\n",
    "print(json.dumps(parsed, indent=2))\n",
    "print(response.headers.get('content-type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering by date is also possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"customerID\": \"A224LOZUTJTM3O\",\n",
      "  \"average\": 4.0,\n",
      "  \"total\": 1\n",
      "}\n",
      "application/json\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/v1/customers/A224LOZUTJTM3O/reviews/stats?date=1390089600\"\n",
    "response = requests.get(url)\n",
    "parsed = json.loads(response.text)\n",
    "print(json.dumps(parsed, indent=2))\n",
    "print(response.headers.get('content-type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clone the repository to your machine.\n",
    "2. Activate your virtual environment inside the directory.\n",
    "3. Run `pip install -r requirements.txt` from the main directory to install required packages.\n",
    "4. Set the `FLASK_APP` environment variable to the path to the app, e.g. from the terminal `export FLASK_APP=src/app.py` (`set FLASK_APP=src/app.py` on Windows).\n",
    "5. Run `flask run` to start the Flask development server on port :5000 by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to deploy \n",
    "(tentatively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. _Somehow Dockerize the app._\n",
    "2. `pip install psycopg2` in the deployment environment.\n",
    "3. Replace the engine on line 12 of app.py: `db_engine = create_engine(“postgresql://name:username@localhost/database_name”)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation:  \n",
    "- Understand the requirements\n",
    "- Fill knowledge gaps\n",
    "- Get to know the database, test SQL queries from SQLite Command Shell and prepare manual test cases \n",
    "- Plan API routes\n",
    "- Plan JSON templates\n",
    " \n",
    "Within the time limit:   \n",
    "- Incrementally develop and manually test the first route\n",
    "\n",
    "Beyond the time limit:     \n",
    "- Set up the second route following the pattern of the first\n",
    "- Prepare the notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1) _your app should be able to connect to a PostgreSQL database in production (with the same schema as the provided SQLite database)_   \n",
    "\n",
    "The presence of two different databases in development and production made me abandon raw SQL querying and explore the ORM capabilities of Flask with SQLAlchemy for scalability and universal back-end compatibility. Given the time constraints, I opted for auto mapping of the table to an object; however, it might generally be better to create a separate model to enforce data types. Also, in real life, PostgreSQL probably has proper date/time data types instead of SQLlite's TEXTs and BIGINTs, but the assumption here is that the types in both schemas are _exactly_ the same.\n",
    "\n",
    "> 2) _your app should have a route that allows end-users to retrieve aggregated review information for a product with a particular ID_  \n",
    "> 3) _your app should have a route that allows end-users to retrieve aggregated review information from a user with a particular ID_\n",
    "\n",
    "I tried using REST API naming conventions. For example:  \n",
    "`v1/products` -- returns all products or gives 404  \n",
    "`v1/products/<productID>` -- returns a specific product or gives 404  \n",
    "The above two resources do not have to exist at a database level. The assumption is that API routes are generally decoupled from a database logic and mainly serve the purpose of readability.  \n",
    "`v1/products/<productID>/reviews` -- returns all reviews for a specific product (can as well be implemented)   \n",
    "`v1/products/<productID>/reviews/stats` -- returns review statistics for a specific product  \n",
    "`v1/products/<productID>/reviews/stats?date=22` -- returns review statistics for a specific product filtered by date\n",
    "\n",
    "I also tried striking a balance between processing complex queries on the db server-side (might be slow), back-end (extra network costs associated with transferring excessive data) and readability. For example, I decided to process the percentage distribution in python for the first route to avoid scanning the table twice or unreadable pipeline code.\n",
    "\n",
    "> 4) _both routes should allow the end-user to optionally filter by review date_ \n",
    "\n",
    "Given the time constraints, I opted for filtering based on the `unixReviewTime` attribute with query strings in the form of `?date=1375056000`. However, an alternative in the form of `?date=07-29-2013` might be more human-readable (and would require either converting the unix time inside the functions or filtering on `reviewTime` with further string parsing).\n",
    "\n",
    "> 5) _your app should follow coding best-practices (at a minimum, it should be well-documented, preferably with unit tests)_\n",
    "\n",
    "Even though I used pytest to enforce TDD in the past, I got a bit confused about how to do it properly for APIs. I assumed that trying to embrace unit testing in this case would slow me down (rather than help me) and decided to rely on manual tests -- comparing return values of the functions with CLI querying of the database using raw SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
